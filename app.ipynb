{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq WhisperSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import Markdown, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vardhanam/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from whisperspeech.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(s2a_ref='collabora/whisperspeech:s2a-q4-tiny-en+pl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "\n",
    "# Assuming `pipe` is your initialized model or pipeline with a generate_to_file method\n",
    "\n",
    "def generate_and_play_audio(text, speaker_url=None):\n",
    "    # Generate a random filename\n",
    "    filename = str(uuid.uuid4()) + \".wav\"\n",
    "    file_location = os.path.join(\"/home/vardhanam/whisper_speech/sound_dump\", filename)\n",
    "\n",
    "    # Generate the audio file from text and save to the specified location\n",
    "    if speaker_url:\n",
    "         pipe.generate_to_file(file_location, text, lang='en', cps=15, speaker=speaker_url)\n",
    "    else:\n",
    "        pipe.generate_to_file(file_location, text, lang ='en', cps =15)\n",
    "\n",
    "    # Return the location of the saved audio file for playback\n",
    "    return file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7862\n",
      "Running on public URL: https://17b51cfa071b6c135e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://17b51cfa071b6c135e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='45' class='' max='749' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      6.01% [45/749 00:01&lt;00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='152' class='' max='152' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [152/152 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=generate_and_play_audio,\n",
    "    inputs=[\n",
    "    gr.Textbox(label=\"Enter your text\"),\n",
    "    gr.Textbox(label=\"Speaker Audio URL (optional)\", placeholder=\"Paste speaker URL here (optional)\")\n",
    "    ],\n",
    "    outputs=gr.Audio(label=\"Your generated audio\"),\n",
    "    title=\"Text to Speech\",\n",
    "    description=\"Enter text to generate speech audio\",\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(server_name=\"0.0.0.0\", share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Pipeline in module whisperspeech.pipeline object:\n",
      "\n",
      "class Pipeline(builtins.object)\n",
      " |  Pipeline(t2s_ref=None, s2a_ref=None, optimize=True, torch_compile=False)\n",
      " |  \n",
      " |  # %% ../nbs/7. Pipeline.ipynb 2\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, t2s_ref=None, s2a_ref=None, optimize=True, torch_compile=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  extract_spk_emb(self, fname)\n",
      " |      Extracts a speaker embedding from the first 30 seconds of the give audio file.\n",
      " |  \n",
      " |  generate(self, text, speaker=None, lang='en', cps=15, step_callback=None)\n",
      " |  \n",
      " |  generate_atoks(self, text, speaker=None, lang='en', cps=15, step_callback=None)\n",
      " |  \n",
      " |  generate_to_file(self, fname, text, speaker=None, lang='en', cps=15, step_callback=None)\n",
      " |  \n",
      " |  generate_to_notebook(self, text, speaker=None, lang='en', cps=15, step_callback=None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  default_speaker = tensor([-0.2929, -0.4503,  0.4155, -0.1417,  0.0...4...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
